{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import mode\n",
    "from IPython import display\n",
    "import seaborn as sns\n",
    "sns.set_style('white')\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import theano\n",
    "import pymc3 as pm\n",
    "import lasagne\n",
    "import theano.tensor as T\n",
    "\n",
    "floatX = theano.config.floatX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_moons, make_blobs, make_circles\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some global variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ADVI_ITERS = 50000\n",
    "N_SAMPLES = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Neural Networks in PyMC3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class PriorWeights(object):\n",
    "    def __init__(self, mode='W', prior='gauss', **params):\n",
    "        self.count = 0\n",
    "        self.prior = prior\n",
    "        self.mode = mode\n",
    "        params.setdefault('std', 1.)\n",
    "        params.setdefault('hyper', None)\n",
    "        self.params = params\n",
    "    def __call__(self, shape):\n",
    "        self.count += 1\n",
    "        if self.params['hyper'] is None:\n",
    "            std = self.params['std']\n",
    "        elif self.params['hyper'] == 'cauchy':\n",
    "            std = pm.HalfCauchy('hyper_%s%d' % (self.mode, self.count), beta=1.)\n",
    "        elif self.params['hyper'] == 'normal':\n",
    "            std = pm.HalfNormal('hyper_%s%d' % (self.mode, self.count), sd=1.)\n",
    "        if self.prior == 'gauss':\n",
    "            return pm.Normal('%s%d' % (self.mode, self.count), mu=0, sd=std, \n",
    "                         testval=np.random.normal(size=shape).astype(np.float64),\n",
    "                         shape=shape)\n",
    "        elif self.prior == 'laplace': \n",
    "            return pm.Laplace('%s%d' % (self.mode, self.count), mu=0, b=std, \n",
    "                         testval=np.random.normal(size=shape).astype(np.float64),\n",
    "                         shape=shape)\n",
    "        elif self.prior == 'flat':\n",
    "            return pm.Flat('%s%d' % (self.mode, self.count), \n",
    "                           testval=np.random.normal(size=shape).astype(np.float64), \n",
    "                           shape=shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_ann(prior_b, prior_W, input_var, target_var, \n",
    "              input_shape, params=[5, 5, 2]):\n",
    "    with pm.Model() as neural_network:\n",
    "        l_in = lasagne.layers.InputLayer(shape=input_shape,\n",
    "                                         input_var=input_var)\n",
    "        n_hid1, n_hid2, n_classes = params\n",
    "        l_hid1 = lasagne.layers.DenseLayer(\n",
    "            l_in, num_units=n_hid1,\n",
    "            nonlinearity=lasagne.nonlinearities.tanh,\n",
    "            b=prior_b,\n",
    "            W=prior_W\n",
    "        )\n",
    "        l_hid2 = lasagne.layers.DenseLayer(\n",
    "            l_hid1, num_units=n_hid2,\n",
    "            nonlinearity=lasagne.nonlinearities.tanh,\n",
    "            b=prior_b,\n",
    "            W=prior_W\n",
    "        )\n",
    "        l_out = lasagne.layers.DenseLayer(\n",
    "            l_hid2, num_units=n_classes,\n",
    "            nonlinearity=lasagne.nonlinearities.softmax,\n",
    "            b=prior_b,\n",
    "            W=prior_W\n",
    "        )\n",
    "\n",
    "        prediction = lasagne.layers.get_output(l_out)\n",
    "        out = pm.Categorical('out', prediction, observed=target_var, \n",
    "                             total_size=y_train.shape[0])\n",
    "    \n",
    "    return neural_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_minibatch(data):\n",
    "    rng = np.random.RandomState(0)\n",
    "    \n",
    "    while True:\n",
    "        ixs = rng.randint(len(data), size=100)\n",
    "        yield data[ixs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_prediction(samples_proba):\n",
    "    return mode(np.argmax(sample_proba(X_test, 500), \n",
    "                          axis=-1), \n",
    "                axis=0).mode[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_data(X, y, filename, visualize=False):\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    ax.scatter(X[y==0, 0], X[y==0, 1], edgecolors='k', label='Class 0')\n",
    "    ax.scatter(X[y==1, 0], X[y==1, 1], color='r', edgecolors='k', label='Class 1')\n",
    "    ax.set_xlabel('Feature 1', fontsize=23)\n",
    "    ax.set_ylabel('Feature 2', fontsize=23)\n",
    "    ax.set_title('Data', fontsize=31)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../pic/' + filename + '.png')\n",
    "    \n",
    "    if not visualize:\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_ppm(grid, ppc, filename, visualize=False):\n",
    "    cmap = sns.diverging_palette(250, 12, s=85, l=25, as_cmap=True)\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    contour = ax.contourf(grid[0], grid[1], ppc[:, :, 1].mean(axis=0).reshape(100, 100), cmap=cmap)\n",
    "    ax.scatter(X_test[y_pred==0, 0], X_test[y_pred==0, 1], edgecolors='k')\n",
    "    ax.scatter(X_test[y_pred==1, 0], X_test[y_pred==1, 1], edgecolors='k', color='r')\n",
    "    cbar = plt.colorbar(contour, ax=ax)\n",
    "    _ = ax.set(xlim=(-3, 3), ylim=(-3, 3))\n",
    "    ax.set_xlabel('Feature 1', fontsize=23)\n",
    "    ax.set_ylabel('Feature 2', fontsize=23)\n",
    "    ax.set_title('Posterior probability', fontsize=31);\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../pic/' + filename + '.png')\n",
    "    \n",
    "    if not visualize:\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_uncertainty(grid, ppc, filename, visualize=False):\n",
    "    cmap = sns.cubehelix_palette(light=1, as_cmap=True)\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    contour = ax.contourf(grid[0], grid[1], ppc[:, :, 1].std(axis=0).reshape(100, 100), cmap=cmap)\n",
    "    ax.scatter(X_test[y_pred==0, 0], X_test[y_pred==0, 1], edgecolors='k')\n",
    "    ax.scatter(X_test[y_pred==1, 0], X_test[y_pred==1, 1], edgecolors='k', color='r')\n",
    "    cbar = plt.colorbar(contour, ax=ax)\n",
    "    _ = ax.set(xlim=(-3, 3), ylim=(-3, 3));\n",
    "    ax.set_xlabel('Feature 1', fontsize=23)\n",
    "    ax.set_ylabel('Feature 2', fontsize=23)\n",
    "    ax.set_title('Uncertainty', fontsize=31);\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../pic/' + filename + '.png')\n",
    "    \n",
    "    if not visualize:\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moons "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X, y = make_moons(noise=0.3, random_state=0, n_samples=1000)\n",
    "X = scale(X)\n",
    "X = X.astype(floatX)\n",
    "y = y.astype(floatX)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.7)\n",
    "input_shape = list(X_train.shape)\n",
    "input_shape[0] = None\n",
    "input_shape = tuple(input_shape)\n",
    "data_name = 'moons'\n",
    "plot_data(X, y, data_name + '/' + data_name + '_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Loss = -28.646: 100%|██████████████████████████████████████████████████| 50000/50000 [00:25<00:00, 1973.98it/s]\n",
      "Finished [100%]: Average Loss = -28.604\n",
      "INFO:pymc3.variational.inference:Finished [100%]: Average Loss = -28.604\n"
     ]
    }
   ],
   "source": [
    "for w_hyper in ['cauchy', 'normal', None]:\n",
    "    for w_prior in ['gauss', 'laplace', 'flat']:\n",
    "        if not ((w_prior == 'flat') and ((w_hyper == 'cauchy') or (w_hyper == 'normal'))):\n",
    "            for b_hyper in ['cauchy', 'normal', None]:\n",
    "                for b_prior in ['gauss', 'laplace', 'flat']:        \n",
    "                    if not ((b_prior == 'flat') and ((b_hyper == 'cauchy') or (b_hyper == 'normal'))):\n",
    "                        minibatch_X = pm.generator(create_minibatch(X_train))\n",
    "                        minibatch_y = pm.generator(create_minibatch(y_train))\n",
    "                        neural_network_minibatch = build_ann(PriorWeights(mode='b', prior=b_prior, hyper=b_hyper), \n",
    "                                                             PriorWeights(mode='W', prior=w_prior, hyper=w_hyper),\n",
    "                                                             minibatch_X, minibatch_y, \n",
    "                                                             input_shape, params=[5, 5, 2])\n",
    "                        with neural_network_minibatch:\n",
    "                            inference = pm.ADVI()\n",
    "                            approx = pm.fit(ADVI_ITERS, method=inference)\n",
    "\n",
    "                        x = T.matrix('X')\n",
    "                        n = T.iscalar('n')\n",
    "                        theano.config.compute_test_value = 'off'\n",
    "                        _sample_proba = approx.sample_node(neural_network_minibatch.out.distribution.p, \n",
    "                                                           size=n,\n",
    "                                                           more_replacements={minibatch_X:x})\n",
    "                        sample_proba = theano.function([x, n], _sample_proba)\n",
    "                        y_pred = get_prediction(sample_proba(X_test, N_SAMPLES))\n",
    "                        accuracy = accuracy_score(y_test, y_pred)\n",
    "                        grid = np.mgrid[-3:3:100j,-3:3:100j].astype(floatX)\n",
    "                        grid_2d = grid.reshape(2, -1).T\n",
    "                        dummy_out = np.ones(grid.shape[1], dtype=np.int8)\n",
    "                        ppc = sample_proba(grid_2d, N_SAMPLES)\n",
    "                        if b_hyper == None:\n",
    "                            b_hyper_ = 'none'\n",
    "                        else:\n",
    "                            b_hyper_ = b_hyper\n",
    "                        if w_hyper == None:\n",
    "                            w_hyper_ = 'none'\n",
    "                        else:\n",
    "                            w_hyper_ = w_hyper\n",
    "                        plot_ppm(grid, ppc, data_name + '/ppm_' + '_'.join([data_name,\n",
    "                                                                            'b', b_hyper_, b_prior,\n",
    "                                                                            'w', w_hyper_, w_prior,\n",
    "                                                                            'acc=%.3f' % accuracy]))\n",
    "                        plot_uncertainty(grid, ppc, data_name + '/uncertainty_' + '_'.join([data_name,\n",
    "                                                                                            'b', b_hyper_, b_prior,\n",
    "                                                                                            'w', w_hyper_, w_prior,\n",
    "                                                                                            'acc=%.3f' % accuracy]))\n",
    "                        display.clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Circles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y = make_circles(noise=0.25, random_state=0, n_samples=1000, factor=0.2)\n",
    "X = scale(X)\n",
    "X = X.astype(floatX)\n",
    "y = y.astype(floatX)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.7)\n",
    "input_shape = list(X_train.shape)\n",
    "input_shape[0] = None\n",
    "input_shape = tuple(input_shape)\n",
    "data_name = 'circles'\n",
    "plot_data(X, y, data_name + '/' + data_name + '_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Loss = -24.4: 100%|████████████████████████████████████████████████████| 50000/50000 [00:15<00:00, 3175.07it/s]\n",
      "Finished [100%]: Average Loss = -24.39\n",
      "INFO:pymc3.variational.inference:Finished [100%]: Average Loss = -24.39\n"
     ]
    }
   ],
   "source": [
    "for w_hyper in ['cauchy', 'normal', None]:\n",
    "    for w_prior in ['gauss', 'laplace', 'flat']:\n",
    "        if not ((w_prior == 'flat') and ((w_hyper == 'cauchy') or (w_hyper == 'normal'))):\n",
    "            for b_hyper in ['cauchy', 'normal', None]:\n",
    "                for b_prior in ['gauss', 'laplace', 'flat']:        \n",
    "                    if not ((b_prior == 'flat') and ((b_hyper == 'cauchy') or (b_hyper == 'normal'))):\n",
    "                        minibatch_X = pm.generator(create_minibatch(X_train))\n",
    "                        minibatch_y = pm.generator(create_minibatch(y_train))\n",
    "                        neural_network_minibatch = build_ann(PriorWeights(mode='b', prior=b_prior, hyper=b_hyper), \n",
    "                                                             PriorWeights(mode='W', prior=w_prior, hyper=w_hyper),\n",
    "                                                             minibatch_X, minibatch_y, \n",
    "                                                             input_shape, params=[5, 5, 2])\n",
    "                        with neural_network_minibatch:\n",
    "                            inference = pm.ADVI()\n",
    "                            approx = pm.fit(ADVI_ITERS, method=inference)\n",
    "\n",
    "                        x = T.matrix('X')\n",
    "                        n = T.iscalar('n')\n",
    "                        theano.config.compute_test_value = 'off'\n",
    "                        _sample_proba = approx.sample_node(neural_network_minibatch.out.distribution.p, \n",
    "                                                           size=n,\n",
    "                                                           more_replacements={minibatch_X:x})\n",
    "                        sample_proba = theano.function([x, n], _sample_proba)\n",
    "                        y_pred = get_prediction(sample_proba(X_test, N_SAMPLES))\n",
    "                        accuracy = accuracy_score(y_test, y_pred)\n",
    "                        grid = np.mgrid[-3:3:100j,-3:3:100j].astype(floatX)\n",
    "                        grid_2d = grid.reshape(2, -1).T\n",
    "                        dummy_out = np.ones(grid.shape[1], dtype=np.int8)\n",
    "                        ppc = sample_proba(grid_2d, N_SAMPLES)\n",
    "                        if b_hyper == None:\n",
    "                            b_hyper_ = 'none'\n",
    "                        else:\n",
    "                            b_hyper_ = b_hyper\n",
    "                        if w_hyper == None:\n",
    "                            w_hyper_ = 'none'\n",
    "                        else:\n",
    "                            w_hyper_ = w_hyper\n",
    "                        plot_ppm(grid, ppc, data_name + '/ppm_' + '_'.join([data_name,\n",
    "                                                                            'b', b_hyper_, b_prior,\n",
    "                                                                            'w', w_hyper_, w_prior,\n",
    "                                                                            'acc=%.3f' % accuracy]))\n",
    "                        plot_uncertainty(grid, ppc, data_name + '/uncertainty_' + '_'.join([data_name,\n",
    "                                                                                            'b', b_hyper_, b_prior,\n",
    "                                                                                            'w', w_hyper_, w_prior,\n",
    "                                                                                            'acc=%.3f' % accuracy]))\n",
    "                        display.clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X, y = make_blobs(cluster_std=1.3, random_state=0, centers=2, n_samples=1000)\n",
    "X = scale(X)\n",
    "X = X.astype(floatX)\n",
    "y = y.astype(floatX)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.7)\n",
    "input_shape = list(X_train.shape)\n",
    "input_shape[0] = None\n",
    "input_shape = tuple(input_shape)\n",
    "data_name = 'blobs'\n",
    "plot_data(X, y, data_name + '/' + data_name + '_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Loss = -38.708: 100%|██████████████████████████████████████████████████| 50000/50000 [00:16<00:00, 2969.10it/s]\n",
      "Finished [100%]: Average Loss = -38.808\n",
      "INFO:pymc3.variational.inference:Finished [100%]: Average Loss = -38.808\n"
     ]
    }
   ],
   "source": [
    "for w_hyper in ['cauchy', 'normal', None]:\n",
    "    for w_prior in ['gauss', 'laplace', 'flat']:\n",
    "        if not ((w_prior == 'flat') and ((w_hyper == 'cauchy') or (w_hyper == 'normal'))):\n",
    "            for b_hyper in ['cauchy', 'normal', None]:\n",
    "                for b_prior in ['gauss', 'laplace', 'flat']:        \n",
    "                    if not ((b_prior == 'flat') and ((b_hyper == 'cauchy') or (b_hyper == 'normal'))):\n",
    "                        minibatch_X = pm.generator(create_minibatch(X_train))\n",
    "                        minibatch_y = pm.generator(create_minibatch(y_train))\n",
    "                        neural_network_minibatch = build_ann(PriorWeights(mode='b', prior=b_prior, hyper=b_hyper), \n",
    "                                                             PriorWeights(mode='W', prior=w_prior, hyper=w_hyper),\n",
    "                                                             minibatch_X, minibatch_y, \n",
    "                                                             input_shape, params=[5, 5, 2])\n",
    "                        with neural_network_minibatch:\n",
    "                            inference = pm.ADVI()\n",
    "                            approx = pm.fit(ADVI_ITERS, method=inference)\n",
    "\n",
    "                        x = T.matrix('X')\n",
    "                        n = T.iscalar('n')\n",
    "                        theano.config.compute_test_value = 'off'\n",
    "                        _sample_proba = approx.sample_node(neural_network_minibatch.out.distribution.p, \n",
    "                                                           size=n,\n",
    "                                                           more_replacements={minibatch_X:x})\n",
    "                        sample_proba = theano.function([x, n], _sample_proba)\n",
    "                        y_pred = get_prediction(sample_proba(X_test, N_SAMPLES))\n",
    "                        accuracy = accuracy_score(y_test, y_pred)\n",
    "                        grid = np.mgrid[-3:3:100j,-3:3:100j].astype(floatX)\n",
    "                        grid_2d = grid.reshape(2, -1).T\n",
    "                        dummy_out = np.ones(grid.shape[1], dtype=np.int8)\n",
    "                        ppc = sample_proba(grid_2d, N_SAMPLES)\n",
    "                        if b_hyper == None:\n",
    "                            b_hyper_ = 'none'\n",
    "                        else:\n",
    "                            b_hyper_ = b_hyper\n",
    "                        if w_hyper == None:\n",
    "                            w_hyper_ = 'none'\n",
    "                        else:\n",
    "                            w_hyper_ = w_hyper\n",
    "                        plot_ppm(grid, ppc, data_name + '/ppm_' + '_'.join([data_name,\n",
    "                                                                            'b', b_hyper_, b_prior,\n",
    "                                                                            'w', w_hyper_, w_prior,\n",
    "                                                                            'acc=%.3f' % accuracy]))\n",
    "                        plot_uncertainty(grid, ppc, data_name + '/uncertainty_' + '_'.join([data_name,\n",
    "                                                                                            'b', b_hyper_, b_prior,\n",
    "                                                                                            'w', w_hyper_, w_prior,\n",
    "                                                                                            'acc=%.3f' % accuracy]))\n",
    "                        display.clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py35]",
   "language": "python",
   "name": "conda-env-py35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
