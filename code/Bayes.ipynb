{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import mode\n",
    "from IPython import display\n",
    "import seaborn as sns\n",
    "sns.set_style('white')\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import theano\n",
    "import pymc3 as pm\n",
    "import lasagne\n",
    "import theano.tensor as T\n",
    "\n",
    "floatX = theano.config.floatX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_moons, make_blobs, make_circles\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some global variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ADVI_ITERS = 50000\n",
    "N_SAMPLES = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Neural Networks in PyMC3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class PriorWeights(object):\n",
    "    def __init__(self, mode='W', prior='gauss', **params):\n",
    "        self.count = 0\n",
    "        self.prior = prior\n",
    "        self.mode = mode\n",
    "        params.setdefault('std', 1.)\n",
    "        params.setdefault('hyper', None)\n",
    "        self.params = params\n",
    "    def __call__(self, shape):\n",
    "        self.count += 1\n",
    "        if self.params['hyper'] is None:\n",
    "            std = self.params['std']\n",
    "        elif self.params['hyper'] == 'cauchy':\n",
    "            std = pm.HalfCauchy('hyper_%s%d' % (self.mode, self.count), beta=1.)\n",
    "        elif self.params['hyper'] == 'normal':\n",
    "            std = pm.HalfNormal('hyper_%s%d' % (self.mode, self.count), sd=1.)\n",
    "        elif self.params['hyper'] == 'invgamma':\n",
    "            std = pm.InverseGamma('hyper_%s%d' % (self.mode, self.count), alpha=1., beta=1.)\n",
    "        if self.prior == 'gauss':\n",
    "            return pm.Normal('%s%d' % (self.mode, self.count), mu=0, sd=std, \n",
    "                         testval=np.random.normal(size=shape).astype(np.float64),\n",
    "                         shape=shape)\n",
    "        elif self.prior == 'laplace': \n",
    "            return pm.Laplace('%s%d' % (self.mode, self.count), mu=0, b=std, \n",
    "                         testval=np.random.normal(size=shape).astype(np.float64),\n",
    "                         shape=shape)\n",
    "        elif self.prior == 'cauchy': \n",
    "            return pm.Cauchy('%s%d' % (self.mode, self.count), alpha=1, beta=1., \n",
    "                         testval=np.random.normal(size=shape).astype(np.float64),\n",
    "                         shape=shape)\n",
    "        elif self.prior == 'flat':\n",
    "            return pm.Flat('%s%d' % (self.mode, self.count), \n",
    "                           testval=np.random.normal(size=shape).astype(np.float64), \n",
    "                           shape=shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_ann(prior_b, prior_W, input_var, target_var, \n",
    "              input_shape, params=[5, 5, 2]):\n",
    "    with pm.Model() as neural_network:\n",
    "        l_in = lasagne.layers.InputLayer(shape=input_shape,\n",
    "                                         input_var=input_var)\n",
    "        n_hid1, n_hid2, n_classes = params\n",
    "        l_hid1 = lasagne.layers.DenseLayer(\n",
    "            l_in, num_units=n_hid1,\n",
    "            nonlinearity=lasagne.nonlinearities.tanh,\n",
    "            b=prior_b,\n",
    "            W=prior_W\n",
    "        )\n",
    "        l_hid2 = lasagne.layers.DenseLayer(\n",
    "            l_hid1, num_units=n_hid2,\n",
    "            nonlinearity=lasagne.nonlinearities.tanh,\n",
    "            b=prior_b,\n",
    "            W=prior_W\n",
    "        )\n",
    "#         l_hid3 = lasagne.layers.DenseLayer(\n",
    "#             l_hid2, num_units=n_hid3,\n",
    "#             nonlinearity=lasagne.nonlinearities.tanh,\n",
    "#             b=prior_b,\n",
    "#             W=prior_W\n",
    "#         )\n",
    "        l_out = lasagne.layers.DenseLayer(\n",
    "            l_hid2, num_units=n_classes,\n",
    "            nonlinearity=lasagne.nonlinearities.softmax,\n",
    "            b=prior_b,\n",
    "            W=prior_W\n",
    "        )\n",
    "\n",
    "        prediction = lasagne.layers.get_output(l_out)\n",
    "        out = pm.Categorical('out', prediction, observed=target_var, \n",
    "                             total_size=y_train.shape[0])\n",
    "    \n",
    "    return neural_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_minibatch(data):\n",
    "    rng = np.random.RandomState(0)\n",
    "    \n",
    "    while True:\n",
    "        ixs = rng.randint(len(data), size=100)\n",
    "        yield data[ixs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_prediction(samples_proba):\n",
    "    return mode(np.argmax(sample_proba(X_test, 500), \n",
    "                          axis=-1), \n",
    "                axis=0).mode[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_data(X, y, filename, visualize=False, save=True):\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    ax.scatter(X[y==0, 0], X[y==0, 1], edgecolors='k', label='Class 0')\n",
    "    ax.scatter(X[y==1, 0], X[y==1, 1], color='r', edgecolors='k', label='Class 1')\n",
    "    ax.set_xlabel('Feature 1', fontsize=23)\n",
    "    ax.set_ylabel('Feature 2', fontsize=23)\n",
    "    ax.set_title('Data', fontsize=31)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save:\n",
    "        plt.savefig('../pic/' + filename + '.png')\n",
    "    \n",
    "    if not visualize:\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_ppm(grid, ppc, filename, visualize=False):\n",
    "    cmap = sns.diverging_palette(250, 12, s=85, l=25, as_cmap=True)\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    contour = ax.contourf(grid[0], grid[1], ppc[:, :, 1].mean(axis=0).reshape(100, 100), cmap=cmap)\n",
    "    ax.scatter(X_test[y_pred==0, 0], X_test[y_pred==0, 1], edgecolors='k')\n",
    "    ax.scatter(X_test[y_pred==1, 0], X_test[y_pred==1, 1], edgecolors='k', color='r')\n",
    "    cbar = plt.colorbar(contour, ax=ax)\n",
    "    _ = ax.set(xlim=(-3, 3), ylim=(-3, 3))\n",
    "    ax.set_xlabel('Feature 1', fontsize=23)\n",
    "    ax.set_ylabel('Feature 2', fontsize=23)\n",
    "    ax.set_title('Posterior probability', fontsize=31);\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../pic/' + filename + '.png')\n",
    "    \n",
    "    if not visualize:\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_uncertainty(grid, ppc, filename, visualize=False):\n",
    "    cmap = sns.cubehelix_palette(light=1, as_cmap=True)\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    contour = ax.contourf(grid[0], grid[1], ppc[:, :, 1].std(axis=0).reshape(100, 100), cmap=cmap)\n",
    "    ax.scatter(X_test[y_pred==0, 0], X_test[y_pred==0, 1], edgecolors='k')\n",
    "    ax.scatter(X_test[y_pred==1, 0], X_test[y_pred==1, 1], edgecolors='k', color='r')\n",
    "    cbar = plt.colorbar(contour, ax=ax)\n",
    "    _ = ax.set(xlim=(-3, 3), ylim=(-3, 3));\n",
    "    ax.set_xlabel('Feature 1', fontsize=23)\n",
    "    ax.set_ylabel('Feature 2', fontsize=23)\n",
    "    ax.set_title('Uncertainty', fontsize=31);\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../pic/' + filename + '.png')\n",
    "    \n",
    "    if not visualize:\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "design = [\n",
    "    ['flat', None, 'flat', None], \n",
    "    ['laplace', None, 'laplace', None],\n",
    "    ['gauss', None, 'gauss', None],\n",
    "    ['cauchy', None, 'cauchy', None],\n",
    "    ['laplace', 'invgamma', 'laplace', 'invgamma'],\n",
    "    ['gauss', 'invgamma', 'gauss', 'invgamma'],\n",
    "    ['cauchy', 'invgamma', 'cauchy', 'invgamma'],\n",
    "]\n",
    "\n",
    "noise = [0.15, 0.25, 0.35, 0.45]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moons "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Loss = 473.21: 100%|██████████| 50000/50000 [00:22<00:00, 2225.70it/s]\n",
      "Finished [100%]: Average Loss = 473.03\n"
     ]
    }
   ],
   "source": [
    "for noise_value in noise:\n",
    "    X, y = make_moons(noise=noise_value, random_state=0, n_samples=2000)\n",
    "    X = scale(X)\n",
    "    X = X.astype(floatX)\n",
    "    y = y.astype(floatX)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.5)\n",
    "\n",
    "    input_shape = list(X_train.shape)\n",
    "    input_shape[0] = None\n",
    "    input_shape = tuple(input_shape)\n",
    "    data_name = 'moons'\n",
    "    plot_data(X, y, data_name + '/' + data_name + '_' + str(noise_value) + '_data')\n",
    "    \n",
    "    for params in design:\n",
    "        b_prior, b_hyper, w_prior, w_hyper = params\n",
    "        minibatch_X = pm.generator(create_minibatch(X_train))\n",
    "        minibatch_y = pm.generator(create_minibatch(y_train))\n",
    "        neural_network_minibatch = build_ann(PriorWeights(mode='b', prior=b_prior, hyper=b_hyper), \n",
    "                                             PriorWeights(mode='W', prior=w_prior, hyper=w_hyper),\n",
    "                                             minibatch_X, minibatch_y, \n",
    "                                             input_shape, params=[5, 5, 2])\n",
    "        with neural_network_minibatch:\n",
    "            inference = pm.ADVI()\n",
    "            approx = pm.fit(ADVI_ITERS, method=inference)\n",
    "\n",
    "        x = T.matrix('X')\n",
    "        n = T.iscalar('n')\n",
    "        theano.config.compute_test_value = 'off'\n",
    "        _sample_proba = approx.sample_node(neural_network_minibatch.out.distribution.p, \n",
    "                                           size=n,\n",
    "                                           more_replacements={minibatch_X:x})\n",
    "        sample_proba = theano.function([x, n], _sample_proba)\n",
    "        y_pred = get_prediction(sample_proba(X_test, N_SAMPLES))\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        grid = np.mgrid[-3:3:100j,-3:3:100j].astype(floatX)\n",
    "        grid_2d = grid.reshape(2, -1).T\n",
    "        dummy_out = np.ones(grid.shape[1], dtype=np.int8)\n",
    "        ppc = sample_proba(grid_2d, N_SAMPLES)\n",
    "        if b_hyper == None:\n",
    "            b_hyper_ = 'none'\n",
    "        else:\n",
    "            b_hyper_ = b_hyper\n",
    "        if w_hyper == None:\n",
    "            w_hyper_ = 'none'\n",
    "        else:\n",
    "            w_hyper_ = w_hyper\n",
    "        plot_ppm(grid, ppc, data_name + '/ppm_' + '_'.join([data_name, str(noise_value),\n",
    "                                                            'acc=%.3f' % accuracy,\n",
    "                                                            'b', b_hyper_, b_prior,\n",
    "                                                            'w', w_hyper_, w_prior]))\n",
    "        plot_uncertainty(grid, ppc, data_name + '/uncertainty_' + '_'.join([data_name, str(noise_value),\n",
    "                                                                            'acc=%.3f' % accuracy,\n",
    "                                                                            'b', b_hyper_, b_prior,\n",
    "                                                                            'w', w_hyper_, w_prior]))\n",
    "        pm.traceplot(approx.sample(500))\n",
    "        plt.savefig('../pic/' + data_name + '/trace_' + '_'.join([data_name, str(noise_value),\n",
    "                                                                'acc=%.3f' % accuracy,\n",
    "                                                            'b', b_hyper_, b_prior,\n",
    "                                                            'w', w_hyper_, w_prior]) + '.png')\n",
    "        plt.close()\n",
    "        display.clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Circles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "design = [\n",
    "    ['flat', None, 'flat', None], \n",
    "    ['laplace', None, 'laplace', None],\n",
    "    ['gauss', None, 'gauss', None],\n",
    "    ['cauchy', None, 'cauchy', None],\n",
    "    ['laplace', 'invgamma', 'laplace', 'invgamma'],\n",
    "    ['gauss', 'invgamma', 'gauss', 'invgamma'],\n",
    "    ['cauchy', 'invgamma', 'cauchy', 'invgamma'],\n",
    "]\n",
    "\n",
    "noise = [0.15, 0.25, 0.35, 0.45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Loss = 571.7: 100%|██████████| 50000/50000 [00:22<00:00, 2199.99it/s] \n",
      "Finished [100%]: Average Loss = 571.6\n"
     ]
    }
   ],
   "source": [
    "for noise_value in noise:\n",
    "    X, y = make_circles(noise=noise_value, random_state=0, n_samples=2000, factor=0.2)\n",
    "    X = scale(X)\n",
    "    X = X.astype(floatX)\n",
    "    y = y.astype(floatX)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.5)\n",
    "    input_shape = list(X_train.shape)\n",
    "    input_shape[0] = None\n",
    "    input_shape = tuple(input_shape)\n",
    "    data_name = 'circles'\n",
    "    plot_data(X, y, data_name + '/' + data_name + '_' + str(noise_value) + '_data')\n",
    "    \n",
    "    for params in design:\n",
    "        b_prior, b_hyper, w_prior, w_hyper = params\n",
    "        minibatch_X = pm.generator(create_minibatch(X_train))\n",
    "        minibatch_y = pm.generator(create_minibatch(y_train))\n",
    "        neural_network_minibatch = build_ann(PriorWeights(mode='b', prior=b_prior, hyper=b_hyper), \n",
    "                                             PriorWeights(mode='W', prior=w_prior, hyper=w_hyper),\n",
    "                                             minibatch_X, minibatch_y, \n",
    "                                             input_shape, params=[5, 5, 2])\n",
    "        with neural_network_minibatch:\n",
    "            inference = pm.ADVI()\n",
    "            approx = pm.fit(ADVI_ITERS, method=inference)\n",
    "\n",
    "        x = T.matrix('X')\n",
    "        n = T.iscalar('n')\n",
    "        theano.config.compute_test_value = 'off'\n",
    "        _sample_proba = approx.sample_node(neural_network_minibatch.out.distribution.p, \n",
    "                                           size=n,\n",
    "                                           more_replacements={minibatch_X:x})\n",
    "        sample_proba = theano.function([x, n], _sample_proba)\n",
    "        y_pred = get_prediction(sample_proba(X_test, N_SAMPLES))\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        grid = np.mgrid[-3:3:100j,-3:3:100j].astype(floatX)\n",
    "        grid_2d = grid.reshape(2, -1).T\n",
    "        dummy_out = np.ones(grid.shape[1], dtype=np.int8)\n",
    "        ppc = sample_proba(grid_2d, N_SAMPLES)\n",
    "        if b_hyper == None:\n",
    "            b_hyper_ = 'none'\n",
    "        else:\n",
    "            b_hyper_ = b_hyper\n",
    "        if w_hyper == None:\n",
    "            w_hyper_ = 'none'\n",
    "        else:\n",
    "            w_hyper_ = w_hyper\n",
    "        plot_ppm(grid, ppc, data_name + '/ppm_' + '_'.join([data_name, str(noise_value),\n",
    "                                                                'acc=%.3f' % accuracy,\n",
    "                                                            'b', b_hyper_, b_prior,\n",
    "                                                            'w', w_hyper_, w_prior]))\n",
    "        plot_uncertainty(grid, ppc, data_name + '/uncertainty_' + '_'.join([data_name, str(noise_value),\n",
    "                                                                'acc=%.3f' % accuracy,\n",
    "                                                            'b', b_hyper_, b_prior,\n",
    "                                                            'w', w_hyper_, w_prior]))\n",
    "        pm.traceplot(approx.sample(500))\n",
    "        plt.savefig('../pic/' + data_name + '/trace_' + '_'.join([data_name, str(noise_value),\n",
    "                                                                'acc=%.3f' % accuracy,\n",
    "                                                            'b', b_hyper_, b_prior,\n",
    "                                                            'w', w_hyper_, w_prior]) + '.png')\n",
    "        plt.close()\n",
    "        display.clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X, y = make_blobs(cluster_std=1, random_state=0, centers=2, n_samples=2000)\n",
    "X = scale(X)\n",
    "X = X.astype(floatX)\n",
    "y = y.astype(floatX)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.5)\n",
    "input_shape = list(X_train.shape)\n",
    "input_shape[0] = None\n",
    "input_shape = tuple(input_shape)\n",
    "data_name = 'blobs'\n",
    "plot_data(X, y, data_name + '/' + data_name + '_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for params in design:\n",
    "    b_prior, b_hyper, w_prior, w_hyper = params\n",
    "    minibatch_X = pm.generator(create_minibatch(X_train))\n",
    "    minibatch_y = pm.generator(create_minibatch(y_train))\n",
    "    neural_network_minibatch = build_ann(PriorWeights(mode='b', prior=b_prior, hyper=b_hyper), \n",
    "                                         PriorWeights(mode='W', prior=w_prior, hyper=w_hyper),\n",
    "                                         minibatch_X, minibatch_y, \n",
    "                                         input_shape, params=[5, 5, 2])\n",
    "    with neural_network_minibatch:\n",
    "        inference = pm.ADVI()\n",
    "        approx = pm.fit(ADVI_ITERS, method=inference)\n",
    "\n",
    "    x = T.matrix('X')\n",
    "    n = T.iscalar('n')\n",
    "    theano.config.compute_test_value = 'off'\n",
    "    _sample_proba = approx.sample_node(neural_network_minibatch.out.distribution.p, \n",
    "                                       size=n,\n",
    "                                       more_replacements={minibatch_X:x})\n",
    "    sample_proba = theano.function([x, n], _sample_proba)\n",
    "    y_pred = get_prediction(sample_proba(X_test, N_SAMPLES))\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    grid = np.mgrid[-3:3:100j,-3:3:100j].astype(floatX)\n",
    "    grid_2d = grid.reshape(2, -1).T\n",
    "    dummy_out = np.ones(grid.shape[1], dtype=np.int8)\n",
    "    ppc = sample_proba(grid_2d, N_SAMPLES)\n",
    "    if b_hyper == None:\n",
    "        b_hyper_ = 'none'\n",
    "    else:\n",
    "        b_hyper_ = b_hyper\n",
    "    if w_hyper == None:\n",
    "        w_hyper_ = 'none'\n",
    "    else:\n",
    "        w_hyper_ = w_hyper\n",
    "    plot_ppm(grid, ppc, data_name + '/ppm_' + '_'.join([data_name,\n",
    "                                                        'b', b_hyper_, b_prior,\n",
    "                                                        'w', w_hyper_, w_prior,\n",
    "                                                        'acc=%.3f' % accuracy]))\n",
    "    plot_uncertainty(grid, ppc, data_name + '/uncertainty_' + '_'.join([data_name,\n",
    "                                                                        'b', b_hyper_, b_prior,\n",
    "                                                                        'w', w_hyper_, w_prior,\n",
    "                                                                        'acc=%.3f' % accuracy]))\n",
    "    display.clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "design = [\n",
    "    ['flat', None, 'flat', None], \n",
    "    ['laplace', None, 'laplace', None],\n",
    "    ['gauss', None, 'gauss', None],\n",
    "    ['cauchy', None, 'cauchy', None],\n",
    "    ['laplace', 'invgamma', 'laplace', 'invgamma'],\n",
    "    ['gauss', 'invgamma', 'gauss', 'invgamma'],\n",
    "    ['cauchy', 'invgamma', 'cauchy', 'invgamma'],\n",
    "]\n",
    "\n",
    "noise = [0.05, 0.1, 0.15, 0.2]\n",
    "\n",
    "ADVI_ITERS = 50000\n",
    "N_SAMPLES = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO (theano.gof.compilelock): Refreshing lock /Users/artembochkarev/.theano/compiledir_Darwin-16.6.0-x86_64-i386-64bit-i386-3.5.2-64/lock_dir/lock\n",
      "Average Loss = 420.9:  51%|█████     | 25623/50000 [00:19<00:16, 1511.92it/s] \n",
      "Interrupted at 25,774 [51%]: Average Loss = 577.75\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-57de0281aa98>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m                                            more_replacements={minibatch_X:x})\n\u001b[1;32m     39\u001b[0m         \u001b[0msample_proba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_sample_proba\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN_SAMPLES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmgrid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100j\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100j\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloatX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/artembochkarev/anaconda/envs/py35/lib/python3.5/site-packages/theano/compile/function_module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    882\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 884\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    885\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/artembochkarev/anaconda/envs/py35/lib/python3.5/site-packages/theano/scan_module/scan_op.py\u001b[0m in \u001b[0;36mrval\u001b[0;34m(p, i, o, n, allow_gc)\u001b[0m\n\u001b[1;32m    961\u001b[0m         def rval(p=p, i=node_input_storage, o=node_output_storage, n=node,\n\u001b[1;32m    962\u001b[0m                  allow_gc=allow_gc):\n\u001b[0;32m--> 963\u001b[0;31m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    964\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m                 \u001b[0mcompute_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/artembochkarev/anaconda/envs/py35/lib/python3.5/site-packages/theano/scan_module/scan_op.py\u001b[0m in \u001b[0;36mp\u001b[0;34m(node, args, outs)\u001b[0m\n\u001b[1;32m    950\u001b[0m                                                 \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m                                                 \u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m                                                 self, node)\n\u001b[0m\u001b[1;32m    953\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mImportError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgof\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMissingGXX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m             \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mtheano/scan_module/scan_perform.pyx\u001b[0m in \u001b[0;36mtheano.scan_module.scan_perform.perform (/Users/artembochkarev/.theano/compiledir_Darwin-16.6.0-x86_64-i386-64bit-i386-3.5.2-64/scan_perform/mod.cpp:4490)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/Users/artembochkarev/anaconda/envs/py35/lib/python3.5/site-packages/theano/gof/op.py\u001b[0m in \u001b[0;36mrval\u001b[0;34m(p, i, o, n)\u001b[0m\n\u001b[1;32m    885\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNoParams\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m             \u001b[0;31m# default arguments are stored in the closure of `rval`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 887\u001b[0;31m             \u001b[0;32mdef\u001b[0m \u001b[0mrval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode_input_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode_output_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    888\u001b[0m                 \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    889\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for noise_value in noise:\n",
    "    size = 1000\n",
    "    X1, y1 = make_circles(noise=noise_value, random_state=0, n_samples=2*size//3, factor=1.)\n",
    "    X2, y2 = make_circles(noise=noise_value, random_state=0, n_samples=size, factor=0.6)\n",
    "    X3, y3 = make_circles(noise=noise_value, random_state=0, n_samples=size//3, factor=0.2)\n",
    "\n",
    "    X = np.concatenate((X1[y1==1], X2[y2==1], X3[y3==1]), axis=0)\n",
    "    y = np.concatenate((np.ones(X1[y1==1].shape[0]), \n",
    "                        np.zeros(X2[y2==1].shape[0]), \n",
    "                        np.ones(X3[y3==1].shape[0])))\n",
    "    X = scale(X)\n",
    "    X = X.astype(floatX)\n",
    "    y = y.astype(floatX)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.5)\n",
    "    input_shape = list(X_train.shape)\n",
    "    input_shape[0] = None\n",
    "    input_shape = tuple(input_shape)\n",
    "    data_name = '3circles'\n",
    "    plot_data(X, y, data_name + '/' + data_name + '_' + str(noise_value) + '_data')\n",
    "    \n",
    "    for params in design:\n",
    "        b_prior, b_hyper, w_prior, w_hyper = params\n",
    "        minibatch_X = pm.generator(create_minibatch(X_train))\n",
    "        minibatch_y = pm.generator(create_minibatch(y_train))\n",
    "        neural_network_minibatch = build_ann(PriorWeights(mode='b', prior=b_prior, hyper=b_hyper), \n",
    "                                             PriorWeights(mode='W', prior=w_prior, hyper=w_hyper),\n",
    "                                             minibatch_X, minibatch_y, \n",
    "                                             input_shape, params=[15, 15, 10, 2])\n",
    "        with neural_network_minibatch:\n",
    "            inference = pm.ADVI()\n",
    "            approx = pm.fit(ADVI_ITERS, method=inference)\n",
    "\n",
    "        x = T.matrix('X')\n",
    "        n = T.iscalar('n')\n",
    "        theano.config.compute_test_value = 'off'\n",
    "        _sample_proba = approx.sample_node(neural_network_minibatch.out.distribution.p, \n",
    "                                           size=n,\n",
    "                                           more_replacements={minibatch_X:x})\n",
    "        sample_proba = theano.function([x, n], _sample_proba)\n",
    "        y_pred = get_prediction(sample_proba(X_test, N_SAMPLES))\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        grid = np.mgrid[-3:3:100j,-3:3:100j].astype(floatX)\n",
    "        grid_2d = grid.reshape(2, -1).T\n",
    "        dummy_out = np.ones(grid.shape[1], dtype=np.int8)\n",
    "        ppc = sample_proba(grid_2d, N_SAMPLES)\n",
    "        if b_hyper == None:\n",
    "            b_hyper_ = 'none'\n",
    "        else:\n",
    "            b_hyper_ = b_hyper\n",
    "        if w_hyper == None:\n",
    "            w_hyper_ = 'none'\n",
    "        else:\n",
    "            w_hyper_ = w_hyper\n",
    "        plot_ppm(grid, ppc, data_name + '/ppm_' + '_'.join([data_name, str(noise_value), 'acc=%.3f' % accuracy,\n",
    "                                                            'b', b_hyper_, b_prior,\n",
    "                                                            'w', w_hyper_, w_prior]))\n",
    "        plot_uncertainty(grid, ppc, data_name + '/uncertainty_' + '_'.join([data_name, str(noise_value), \n",
    "                                                                            'acc=%.3f' % accuracy,\n",
    "                                                                            'b', b_hyper_, b_prior,\n",
    "                                                                            'w', w_hyper_, w_prior]))\n",
    "        display.clear_output(wait=True)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py35]",
   "language": "python",
   "name": "conda-env-py35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
