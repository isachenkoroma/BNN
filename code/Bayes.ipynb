{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import mode\n",
    "from IPython import display\n",
    "import seaborn as sns\n",
    "sns.set_style('white')\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import theano\n",
    "import pymc3 as pm\n",
    "import lasagne\n",
    "import theano.tensor as T\n",
    "\n",
    "floatX = theano.config.floatX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_moons, make_blobs, make_circles\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some global variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ADVI_ITERS = 50000\n",
    "N_SAMPLES = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Neural Networks in PyMC3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class PriorWeights(object):\n",
    "    def __init__(self, mode='W', prior='gauss', **params):\n",
    "        self.count = 0\n",
    "        self.prior = prior\n",
    "        self.mode = mode\n",
    "        params.setdefault('std', 1.)\n",
    "        params.setdefault('hyper', None)\n",
    "        self.params = params\n",
    "    def __call__(self, shape):\n",
    "        self.count += 1\n",
    "        if self.params['hyper'] is None:\n",
    "            std = self.params['std']\n",
    "        elif self.params['hyper'] == 'cauchy':\n",
    "            std = pm.HalfCauchy('hyper_%s%d' % (self.mode, self.count), beta=1.)\n",
    "        elif self.params['hyper'] == 'normal':\n",
    "            std = pm.HalfNormal('hyper_%s%d' % (self.mode, self.count), sd=1.)\n",
    "        elif self.params['hyper'] == 'invgamma':\n",
    "            std = pm.InverseGamma('hyper_%s%d' % (self.mode, self.count), alpha=1., beta=1.)\n",
    "        if self.prior == 'gauss':\n",
    "            return pm.Normal('%s%d' % (self.mode, self.count), mu=0, sd=std, \n",
    "                         testval=np.random.normal(size=shape).astype(np.float64),\n",
    "                         shape=shape)\n",
    "        elif self.prior == 'laplace': \n",
    "            return pm.Laplace('%s%d' % (self.mode, self.count), mu=0, b=std, \n",
    "                         testval=np.random.normal(size=shape).astype(np.float64),\n",
    "                         shape=shape)\n",
    "        elif self.prior == 'cauchy': \n",
    "            return pm.Cauchy('%s%d' % (self.mode, self.count), alpha=1, beta=1., \n",
    "                         testval=np.random.normal(size=shape).astype(np.float64),\n",
    "                         shape=shape)\n",
    "        elif self.prior == 'flat':\n",
    "            return pm.Flat('%s%d' % (self.mode, self.count), \n",
    "                           testval=np.random.normal(size=shape).astype(np.float64), \n",
    "                           shape=shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_ann(prior_b, prior_W, input_var, target_var, \n",
    "              input_shape, params=[5, 5, 2]):\n",
    "    with pm.Model() as neural_network:\n",
    "        l_in = lasagne.layers.InputLayer(shape=input_shape,\n",
    "                                         input_var=input_var)\n",
    "        n_hid1, n_hid2, n_classes = params\n",
    "        l_hid1 = lasagne.layers.DenseLayer(\n",
    "            l_in, num_units=n_hid1,\n",
    "            nonlinearity=lasagne.nonlinearities.tanh,\n",
    "            b=prior_b,\n",
    "            W=prior_W\n",
    "        )\n",
    "        l_hid2 = lasagne.layers.DenseLayer(\n",
    "            l_hid1, num_units=n_hid2,\n",
    "            nonlinearity=lasagne.nonlinearities.tanh,\n",
    "            b=prior_b,\n",
    "            W=prior_W\n",
    "        )\n",
    "        l_out = lasagne.layers.DenseLayer(\n",
    "            l_hid2, num_units=n_classes,\n",
    "            nonlinearity=lasagne.nonlinearities.softmax,\n",
    "            b=prior_b,\n",
    "            W=prior_W\n",
    "        )\n",
    "\n",
    "        prediction = lasagne.layers.get_output(l_out)\n",
    "        out = pm.Categorical('out', prediction, observed=target_var, \n",
    "                             total_size=y_train.shape[0])\n",
    "    \n",
    "    return neural_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_minibatch(data):\n",
    "    rng = np.random.RandomState(0)\n",
    "    \n",
    "    while True:\n",
    "        ixs = rng.randint(len(data), size=100)\n",
    "        yield data[ixs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_prediction(samples_proba):\n",
    "    return mode(np.argmax(sample_proba(X_test, 500), \n",
    "                          axis=-1), \n",
    "                axis=0).mode[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_data(X, y, filename, visualize=False, save=True):\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    ax.scatter(X[y==0, 0], X[y==0, 1], edgecolors='k', label='Class 0')\n",
    "    ax.scatter(X[y==1, 0], X[y==1, 1], color='r', edgecolors='k', label='Class 1')\n",
    "    ax.set_xlabel('Feature 1', fontsize=23)\n",
    "    ax.set_ylabel('Feature 2', fontsize=23)\n",
    "    ax.set_title('Data', fontsize=31)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save:\n",
    "        plt.savefig('../pic/' + filename + '.png')\n",
    "    \n",
    "    if not visualize:\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_ppm(grid, ppc, filename, visualize=False):\n",
    "    cmap = sns.diverging_palette(250, 12, s=85, l=25, as_cmap=True)\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    contour = ax.contourf(grid[0], grid[1], ppc[:, :, 1].mean(axis=0).reshape(100, 100), cmap=cmap)\n",
    "    ax.scatter(X_test[y_pred==0, 0], X_test[y_pred==0, 1], edgecolors='k')\n",
    "    ax.scatter(X_test[y_pred==1, 0], X_test[y_pred==1, 1], edgecolors='k', color='r')\n",
    "    cbar = plt.colorbar(contour, ax=ax)\n",
    "    _ = ax.set(xlim=(-3, 3), ylim=(-3, 3))\n",
    "    ax.set_xlabel('Feature 1', fontsize=23)\n",
    "    ax.set_ylabel('Feature 2', fontsize=23)\n",
    "    ax.set_title('Posterior probability', fontsize=31);\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../pic/' + filename + '.png')\n",
    "    \n",
    "    if not visualize:\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_uncertainty(grid, ppc, filename, visualize=False):\n",
    "    cmap = sns.cubehelix_palette(light=1, as_cmap=True)\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    contour = ax.contourf(grid[0], grid[1], ppc[:, :, 1].std(axis=0).reshape(100, 100), cmap=cmap)\n",
    "    ax.scatter(X_test[y_pred==0, 0], X_test[y_pred==0, 1], edgecolors='k')\n",
    "    ax.scatter(X_test[y_pred==1, 0], X_test[y_pred==1, 1], edgecolors='k', color='r')\n",
    "    cbar = plt.colorbar(contour, ax=ax)\n",
    "    _ = ax.set(xlim=(-3, 3), ylim=(-3, 3));\n",
    "    ax.set_xlabel('Feature 1', fontsize=23)\n",
    "    ax.set_ylabel('Feature 2', fontsize=23)\n",
    "    ax.set_title('Uncertainty', fontsize=31);\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../pic/' + filename + '.png')\n",
    "    \n",
    "    if not visualize:\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "design = [\n",
    "    ['flat', None, 'flat', None], \n",
    "    ['flat', None, 'cauchy', None], \n",
    "    ['flat', None, 'laplace', None],\n",
    "    ['flat', None, 'gauss', None],\n",
    "    ['flat', None, 'gauss', 'cauchy'],\n",
    "    ['flat', None, 'gauss', 'invgamma']\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moons "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X, y = make_moons(noise=0.4, random_state=0, n_samples=1200)\n",
    "X = scale(X)\n",
    "X = X.astype(floatX)\n",
    "y = y.astype(floatX)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.7)\n",
    "input_shape = list(X_train.shape)\n",
    "input_shape[0] = None\n",
    "input_shape = tuple(input_shape)\n",
    "data_name = 'moons'\n",
    "plot_data(X, y, data_name + '/' + data_name + '_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Loss = 145.17: 100%|███████████████████████████████████████████████████| 50000/50000 [00:19<00:00, 2525.18it/s]\n",
      "Finished [100%]: Average Loss = 145.25\n"
     ]
    }
   ],
   "source": [
    "for params in design:\n",
    "    b_prior, b_hyper, w_prior, w_hyper = params\n",
    "    minibatch_X = pm.generator(create_minibatch(X_train))\n",
    "    minibatch_y = pm.generator(create_minibatch(y_train))\n",
    "    neural_network_minibatch = build_ann(PriorWeights(mode='b', prior=b_prior, hyper=b_hyper), \n",
    "                                         PriorWeights(mode='W', prior=w_prior, hyper=w_hyper),\n",
    "                                         minibatch_X, minibatch_y, \n",
    "                                         input_shape, params=[5, 5, 2])\n",
    "    with neural_network_minibatch:\n",
    "        inference = pm.ADVI()\n",
    "        approx = pm.fit(ADVI_ITERS, method=inference)\n",
    "\n",
    "    x = T.matrix('X')\n",
    "    n = T.iscalar('n')\n",
    "    theano.config.compute_test_value = 'off'\n",
    "    _sample_proba = approx.sample_node(neural_network_minibatch.out.distribution.p, \n",
    "                                       size=n,\n",
    "                                       more_replacements={minibatch_X:x})\n",
    "    sample_proba = theano.function([x, n], _sample_proba)\n",
    "    y_pred = get_prediction(sample_proba(X_test, N_SAMPLES))\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    grid = np.mgrid[-3:3:100j,-3:3:100j].astype(floatX)\n",
    "    grid_2d = grid.reshape(2, -1).T\n",
    "    dummy_out = np.ones(grid.shape[1], dtype=np.int8)\n",
    "    ppc = sample_proba(grid_2d, N_SAMPLES)\n",
    "    if b_hyper == None:\n",
    "        b_hyper_ = 'none'\n",
    "    else:\n",
    "        b_hyper_ = b_hyper\n",
    "    if w_hyper == None:\n",
    "        w_hyper_ = 'none'\n",
    "    else:\n",
    "        w_hyper_ = w_hyper\n",
    "    plot_ppm(grid, ppc, data_name + '/ppm_' + '_'.join([data_name,\n",
    "                                                        'b', b_hyper_, b_prior,\n",
    "                                                        'w', w_hyper_, w_prior,\n",
    "                                                        'acc=%.3f' % accuracy]))\n",
    "    plot_uncertainty(grid, ppc, data_name + '/uncertainty_' + '_'.join([data_name,\n",
    "                                                                        'b', b_hyper_, b_prior,\n",
    "                                                                        'w', w_hyper_, w_prior,\n",
    "                                                                        'acc=%.3f' % accuracy]))\n",
    "    display.clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Circles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y = make_circles(noise=0.333, random_state=0, n_samples=1000, factor=0.2)\n",
    "X = scale(X)\n",
    "X = X.astype(floatX)\n",
    "y = y.astype(floatX)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.7)\n",
    "input_shape = list(X_train.shape)\n",
    "input_shape[0] = None\n",
    "input_shape = tuple(input_shape)\n",
    "data_name = 'circles'\n",
    "plot_data(X, y, data_name + '/' + data_name + '_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Loss = 148.31: 100%|███████████████████████████████████████████████████| 50000/50000 [00:21<00:00, 2358.97it/s]\n",
      "Finished [100%]: Average Loss = 148.26\n"
     ]
    }
   ],
   "source": [
    "for params in design:\n",
    "    b_prior, b_hyper, w_prior, w_hyper = params\n",
    "    minibatch_X = pm.generator(create_minibatch(X_train))\n",
    "    minibatch_y = pm.generator(create_minibatch(y_train))\n",
    "    neural_network_minibatch = build_ann(PriorWeights(mode='b', prior=b_prior, hyper=b_hyper), \n",
    "                                         PriorWeights(mode='W', prior=w_prior, hyper=w_hyper),\n",
    "                                         minibatch_X, minibatch_y, \n",
    "                                         input_shape, params=[5, 5, 2])\n",
    "    with neural_network_minibatch:\n",
    "        inference = pm.ADVI()\n",
    "        approx = pm.fit(ADVI_ITERS, method=inference)\n",
    "\n",
    "    x = T.matrix('X')\n",
    "    n = T.iscalar('n')\n",
    "    theano.config.compute_test_value = 'off'\n",
    "    _sample_proba = approx.sample_node(neural_network_minibatch.out.distribution.p, \n",
    "                                       size=n,\n",
    "                                       more_replacements={minibatch_X:x})\n",
    "    sample_proba = theano.function([x, n], _sample_proba)\n",
    "    y_pred = get_prediction(sample_proba(X_test, N_SAMPLES))\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    grid = np.mgrid[-3:3:100j,-3:3:100j].astype(floatX)\n",
    "    grid_2d = grid.reshape(2, -1).T\n",
    "    dummy_out = np.ones(grid.shape[1], dtype=np.int8)\n",
    "    ppc = sample_proba(grid_2d, N_SAMPLES)\n",
    "    if b_hyper == None:\n",
    "        b_hyper_ = 'none'\n",
    "    else:\n",
    "        b_hyper_ = b_hyper\n",
    "    if w_hyper == None:\n",
    "        w_hyper_ = 'none'\n",
    "    else:\n",
    "        w_hyper_ = w_hyper\n",
    "    plot_ppm(grid, ppc, data_name + '/ppm_' + '_'.join([data_name,\n",
    "                                                        'b', b_hyper_, b_prior,\n",
    "                                                        'w', w_hyper_, w_prior,\n",
    "                                                        'acc=%.3f' % accuracy]))\n",
    "    plot_uncertainty(grid, ppc, data_name + '/uncertainty_' + '_'.join([data_name,\n",
    "                                                                        'b', b_hyper_, b_prior,\n",
    "                                                                        'w', w_hyper_, w_prior,\n",
    "                                                                        'acc=%.3f' % accuracy]))\n",
    "    display.clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X, y = make_blobs(cluster_std=1.9, random_state=0, centers=2, n_samples=1000)\n",
    "X = scale(X)\n",
    "X = X.astype(floatX)\n",
    "y = y.astype(floatX)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.7)\n",
    "input_shape = list(X_train.shape)\n",
    "input_shape[0] = None\n",
    "input_shape = tuple(input_shape)\n",
    "data_name = 'blobs'\n",
    "plot_data(X, y, data_name + '/' + data_name + '_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for params in design:\n",
    "    b_prior, b_hyper, w_prior, w_hyper = params\n",
    "    minibatch_X = pm.generator(create_minibatch(X_train))\n",
    "    minibatch_y = pm.generator(create_minibatch(y_train))\n",
    "    neural_network_minibatch = build_ann(PriorWeights(mode='b', prior=b_prior, hyper=b_hyper), \n",
    "                                         PriorWeights(mode='W', prior=w_prior, hyper=w_hyper),\n",
    "                                         minibatch_X, minibatch_y, \n",
    "                                         input_shape, params=[5, 5, 2])\n",
    "    with neural_network_minibatch:\n",
    "        inference = pm.ADVI()\n",
    "        approx = pm.fit(ADVI_ITERS, method=inference)\n",
    "\n",
    "    x = T.matrix('X')\n",
    "    n = T.iscalar('n')\n",
    "    theano.config.compute_test_value = 'off'\n",
    "    _sample_proba = approx.sample_node(neural_network_minibatch.out.distribution.p, \n",
    "                                       size=n,\n",
    "                                       more_replacements={minibatch_X:x})\n",
    "    sample_proba = theano.function([x, n], _sample_proba)\n",
    "    y_pred = get_prediction(sample_proba(X_test, N_SAMPLES))\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    grid = np.mgrid[-3:3:100j,-3:3:100j].astype(floatX)\n",
    "    grid_2d = grid.reshape(2, -1).T\n",
    "    dummy_out = np.ones(grid.shape[1], dtype=np.int8)\n",
    "    ppc = sample_proba(grid_2d, N_SAMPLES)\n",
    "    if b_hyper == None:\n",
    "        b_hyper_ = 'none'\n",
    "    else:\n",
    "        b_hyper_ = b_hyper\n",
    "    if w_hyper == None:\n",
    "        w_hyper_ = 'none'\n",
    "    else:\n",
    "        w_hyper_ = w_hyper\n",
    "    plot_ppm(grid, ppc, data_name + '/ppm_' + '_'.join([data_name,\n",
    "                                                        'b', b_hyper_, b_prior,\n",
    "                                                        'w', w_hyper_, w_prior,\n",
    "                                                        'acc=%.3f' % accuracy]))\n",
    "    plot_uncertainty(grid, ppc, data_name + '/uncertainty_' + '_'.join([data_name,\n",
    "                                                                        'b', b_hyper_, b_prior,\n",
    "                                                                        'w', w_hyper_, w_prior,\n",
    "                                                                        'acc=%.3f' % accuracy]))\n",
    "    display.clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "size = 6000\n",
    "X1, y1 = make_circles(noise=0.1, random_state=0, n_samples=3*size//4, factor=1.)\n",
    "X2, y2 = make_circles(noise=0.1, random_state=0, n_samples=size, factor=0.6)\n",
    "X3, y3 = make_circles(noise=0.1, random_state=0, n_samples=size//4, factor=0.2)\n",
    "\n",
    "X = np.concatenate((X1[y1==1], X2[y2==1], X3[y3==1]), axis=0)\n",
    "y = np.concatenate((np.ones(X1[y1==1].shape[0]), \n",
    "                    np.zeros(X2[y2==1].shape[0]), \n",
    "                    np.ones(X3[y3==1].shape[0])))\n",
    "X = scale(X)\n",
    "X = X.astype(floatX)\n",
    "y = y.astype(floatX)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.7)\n",
    "input_shape = list(X_train.shape)\n",
    "input_shape[0] = None\n",
    "input_shape = tuple(input_shape)\n",
    "data_name = '3circles'\n",
    "plot_data(X, y, data_name + '/' + data_name + '_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Loss = 864.38: 100%|███████████████████████████████████████████████████| 50000/50000 [00:35<00:00, 1408.45it/s]\n",
      "Finished [100%]: Average Loss = 864.34\n"
     ]
    }
   ],
   "source": [
    "for params in design:\n",
    "    b_prior, b_hyper, w_prior, w_hyper = params\n",
    "    minibatch_X = pm.generator(create_minibatch(X_train))\n",
    "    minibatch_y = pm.generator(create_minibatch(y_train))\n",
    "    neural_network_minibatch = build_ann(PriorWeights(mode='b', prior=b_prior, hyper=b_hyper), \n",
    "                                         PriorWeights(mode='W', prior=w_prior, hyper=w_hyper),\n",
    "                                         minibatch_X, minibatch_y, \n",
    "                                         input_shape, params=[15, 15, 2])\n",
    "    with neural_network_minibatch:\n",
    "        inference = pm.ADVI()\n",
    "        approx = pm.fit(ADVI_ITERS, method=inference)\n",
    "\n",
    "    x = T.matrix('X')\n",
    "    n = T.iscalar('n')\n",
    "    theano.config.compute_test_value = 'off'\n",
    "    _sample_proba = approx.sample_node(neural_network_minibatch.out.distribution.p, \n",
    "                                       size=n,\n",
    "                                       more_replacements={minibatch_X:x})\n",
    "    sample_proba = theano.function([x, n], _sample_proba)\n",
    "    y_pred = get_prediction(sample_proba(X_test, N_SAMPLES))\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    grid = np.mgrid[-3:3:100j,-3:3:100j].astype(floatX)\n",
    "    grid_2d = grid.reshape(2, -1).T\n",
    "    dummy_out = np.ones(grid.shape[1], dtype=np.int8)\n",
    "    ppc = sample_proba(grid_2d, N_SAMPLES)\n",
    "    if b_hyper == None:\n",
    "        b_hyper_ = 'none'\n",
    "    else:\n",
    "        b_hyper_ = b_hyper\n",
    "    if w_hyper == None:\n",
    "        w_hyper_ = 'none'\n",
    "    else:\n",
    "        w_hyper_ = w_hyper\n",
    "    plot_ppm(grid, ppc, data_name + '/ppm_' + '_'.join([data_name,\n",
    "                                                        'b', b_hyper_, b_prior,\n",
    "                                                        'w', w_hyper_, w_prior,\n",
    "                                                        'acc=%.3f' % accuracy]))\n",
    "    plot_uncertainty(grid, ppc, data_name + '/uncertainty_' + '_'.join([data_name,\n",
    "                                                                        'b', b_hyper_, b_prior,\n",
    "                                                                        'w', w_hyper_, w_prior,\n",
    "                                                                        'acc=%.3f' % accuracy]))\n",
    "    display.clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py35]",
   "language": "python",
   "name": "conda-env-py35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
