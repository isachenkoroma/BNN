{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import mode\n",
    "import scipy\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import mode\n",
    "import seaborn as sns\n",
    "sns.set_style('white')\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "WARNING:theano.sandbox.cuda:The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "Using gpu device 0: GRID K520 (CNMeM is disabled, cuDNN 5005)\n"
     ]
    }
   ],
   "source": [
    "import theano\n",
    "import pymc3 as pm\n",
    "import lasagne\n",
    "import theano.tensor as T\n",
    "\n",
    "floatX = theano.config.floatX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import theano\n",
    "import pymc3 as pm\n",
    "import lasagne\n",
    "from lasagne.utils import floatX\n",
    "from lasagne.layers import InputLayer, DenseLayer, NonlinearityLayer, DropoutLayer\n",
    "from lasagne.layers import Pool2DLayer as PoolLayer\n",
    "from lasagne.layers import Conv2DLayer as ConvLayer\n",
    "from lasagne.nonlinearities import rectify, softmax\n",
    "import theano.tensor as T\n",
    "\n",
    "floatX = theano.config.floatX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(img, h=64, w=64):\n",
    "    img = img.astype('float32')\n",
    "    \n",
    "    img_resized = np.zeros(shape=(1, 3, h, w))\n",
    "    img_resized[0, 2, :, :] = cv2.resize(img[:, :, 0] - MEAN_VALUES[2], (h, w))\n",
    "    img_resized[0, 1, :, :] = cv2.resize(img[:, :, 1] - MEAN_VALUES[1], (h, w)) \n",
    "    img_resized[0, 0, :, :] = cv2.resize(img[:, :, 2] - MEAN_VALUES[0], (h, w)) \n",
    "    \n",
    "    return img_resized.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dir_path = 'data/train_subset/'\n",
    "\n",
    "file_names = os.listdir(dir_path)\n",
    "n_objects = len(file_names)\n",
    "\n",
    "y_train = []\n",
    "X_train = np.zeros(shape=(n_objects, 3, 64, 64), dtype='float32')\n",
    "\n",
    "MEAN_VALUES = [0, 0, 0]\n",
    "for i, f in enumerate(file_names):\n",
    "    img = scipy.misc.imread(dir_path + f)\n",
    "    y_train.append(f[:3] == 'cat')\n",
    "    MEAN_VALUES[2] += img[:, :, 0].mean()\n",
    "    MEAN_VALUES[1] += img[:, :, 1].mean()\n",
    "    MEAN_VALUES[0] += img[:, :, 2].mean()\n",
    "\n",
    "MEAN_VALUES = 1. * np.array(MEAN_VALUES) / n_objects\n",
    "y_train = np.array(y_train, dtype='int32')\n",
    "\n",
    "for i, f in enumerate(file_names):\n",
    "    img = scipy.misc.imread(dir_path + f)\n",
    "    X_train[i] = preprocess(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 3, 64, 64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape = list(X_train.shape)\n",
    "input_shape[0] = None\n",
    "input_shape = tuple(input_shape)\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PriorWeights(object):\n",
    "    def __init__(self, mode='W', prior='gauss', **params):\n",
    "        self.count = 0\n",
    "        self.prior = prior\n",
    "        self.mode = mode\n",
    "        params.setdefault('std', 1.)\n",
    "        params.setdefault('hyper', None)\n",
    "        self.params = params\n",
    "    def __call__(self, shape):\n",
    "        self.count += 1\n",
    "        if self.params['hyper'] is None:\n",
    "            std = self.params['std']\n",
    "        elif self.params['hyper'] == 'cauchy':\n",
    "            std = pm.HalfCauchy('hyper_%s%d' % (self.mode, self.count), beta=1.)\n",
    "        elif self.params['hyper'] == 'normal':\n",
    "            std = pm.HalfNormal('hyper_%s%d' % (self.mode, self.count), mu=0., sd=1.)\n",
    "        elif self.params['hyper'] == 'flat':\n",
    "            std = pm.Flat()\n",
    "        if self.prior == 'gauss':\n",
    "            return pm.Normal('%s%d' % (self.mode, self.count), mu=0, sd=std, \n",
    "                         testval=np.random.normal(size=shape).astype(np.float64),\n",
    "                         shape=shape)\n",
    "        elif self.prior == 'laplace': \n",
    "            return pm.Laplace('%s%d' % (self.mode, self.count), mu=0, b=std, \n",
    "                         testval=np.random.normal(size=shape).astype(np.float64),\n",
    "                         shape=shape)\n",
    "        elif self.prior == 'flat':\n",
    "            return pm.Flat('%s%d' % (self.mode, self.count), \n",
    "                           testval=np.random.normal(size=shape).astype(np.float64), \n",
    "                           shape=shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_ann(prior_b, prior_W, input_var, target_var, \n",
    "              input_shape, params=[176, 64, 10]):\n",
    "    \n",
    "    n_hid1, n_hid2, n_classes = params\n",
    "    with pm.Model() as neural_network:\n",
    "        l_in = lasagne.layers.InputLayer(shape=input_shape,\n",
    "                                         input_var=input_var)\n",
    "        l_conv1 = lasagne.layers.Conv2DLayer(\n",
    "                            l_in, num_filters=32, filter_size=(5, 5),\n",
    "                            b=prior_b, W=prior_W,\n",
    "                            nonlinearity=lasagne.nonlinearities.tanh)\n",
    "        \n",
    "        l_pool1 = lasagne.layers.MaxPool2DLayer(l_conv1, pool_size=(2, 2))\n",
    "        \n",
    "        l_conv2 = lasagne.layers.Conv2DLayer(\n",
    "                            l_pool1, num_filters=32, filter_size=(5, 5),\n",
    "                            b=prior_b, W=prior_W,\n",
    "                            nonlinearity=lasagne.nonlinearities.tanh)\n",
    "\n",
    "        l_pool2 = lasagne.layers.MaxPool2DLayer(l_conv2, pool_size=(2, 2))\n",
    "\n",
    "        l_dense1 = lasagne.layers.DenseLayer(\n",
    "                            l_pool2, num_units=n_hid1,\n",
    "                            b=prior_b, W=prior_W,\n",
    "                            nonlinearity=lasagne.nonlinearities.tanh)\n",
    "\n",
    "#         l_dense2 = lasagne.layers.DenseLayer(\n",
    "#                             l_dense1, num_units=n_hid2,\n",
    "#                             b=prior_b, W=prior_W,\n",
    "#                             nonlinearity=lasagne.nonlinearities.tanh)\n",
    "\n",
    "        l_out = lasagne.layers.DenseLayer(\n",
    "                            l_dense1, num_units=n_classes,\n",
    "                            b=prior_b, W=prior_W,\n",
    "                            nonlinearity=lasagne.nonlinearities.softmax,\n",
    "        )\n",
    "\n",
    "        prediction = lasagne.layers.get_output(l_out)\n",
    "        \n",
    "        out = pm.Categorical('out', prediction,\n",
    "                           observed=target_var,\n",
    "                           total_size=y_train.shape[0])\n",
    "    \n",
    "    return neural_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_minibatch(data):\n",
    "    rng = np.random.RandomState(0)\n",
    "    \n",
    "    while True:\n",
    "        ixs = rng.randint(len(data), size=100)\n",
    "        yield data[ixs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_prediction(samples_proba):\n",
    "    return mode(np.argmax(sample_proba(X_test, 500), \n",
    "                          axis=-1), axis=0).mode[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "minibatch_X = pm.generator(create_minibatch(X_train))\n",
    "minibatch_y = pm.generator(create_minibatch(y_train))\n",
    "neural_network_minibatch = build_ann(PriorWeights(mode='b', prior='gauss', std=0.1), \n",
    "                                     PriorWeights(mode='W', prior='gauss', std=0.1),\n",
    "                                     minibatch_X, minibatch_y, \n",
    "                                     input_shape, params=[64, 64, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ADVI_ITERS = 25000\n",
    "N_SAMPLES = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Loss = 4,711.3: 100%|██████████| 25000/25000 [24:02<00:00, 17.36it/s]\n"
     ]
    }
   ],
   "source": [
    "with neural_network_minibatch:\n",
    "    inference = pm.ADVI()\n",
    "    approx = pm.fit(ADVI_ITERS, method=inference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = T.tensor4('X')\n",
    "n = T.iscalar('n')\n",
    "theano.config.compute_test_value = 'off'\n",
    "_sample_proba = approx.sample_node(neural_network_minibatch.out.distribution.p, \n",
    "                                   size=n,\n",
    "                                   more_replacements={minibatch_X:x})\n",
    "prediction = approx.apply_replacements(neural_network_minibatch.out.distribution.p, \n",
    "                                    deterministic=True, \n",
    "                                    more_replacements={minibatch_X:x})\n",
    "\n",
    "sample_proba = theano.function([x, n], _sample_proba)\n",
    "map_proba = theano.function([x], prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred_MAP = np.argmax(map_proba(X_test), axis=1)\n",
    "error_under_MAP = y_pred_MAP != y_test\n",
    "error_rate_under_MAP = error_under_MAP.mean()\n",
    "\n",
    "y_preds_posterior = sample_proba(X_test, 100)\n",
    "y_pred_posterior = mode(np.argmax(y_preds_posterior, axis=-1), axis=0).mode[0]\n",
    "error_under_posterior = y_pred_posterior != y_test\n",
    "error_rate_under_posterior = error_under_posterior.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP                      : 0.500000\n",
      "predictive posterior mode: 0.478667\n"
     ]
    }
   ],
   "source": [
    "print('MAP                      : %f' % error_rate_under_MAP)\n",
    "print('predictive posterior mode: %f' % error_rate_under_posterior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "1482\n",
      "1500\n"
     ]
    }
   ],
   "source": [
    "print np.sum(y_pred_MAP==1)\n",
    "print np.sum(y_pred_MAP==0)\n",
    "print y_pred_MAP.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
