{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import mode\n",
    "import scipy\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "WARNING:theano.sandbox.cuda:The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "Using gpu device 0: GRID K520 (CNMeM is disabled, cuDNN 5005)\n"
     ]
    }
   ],
   "source": [
    "import theano\n",
    "import pymc3 as pm\n",
    "import lasagne\n",
    "from lasagne.utils import floatX\n",
    "from lasagne.layers import InputLayer, DenseLayer, NonlinearityLayer, DropoutLayer\n",
    "from lasagne.layers import Pool2DLayer as PoolLayer\n",
    "from lasagne.layers import Conv2DLayer as ConvLayer\n",
    "from lasagne.nonlinearities import rectify, softmax\n",
    "import theano.tensor as T\n",
    "\n",
    "floatX = theano.config.floatX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(img, h=32, w=32):\n",
    "    img = img.astype('float32')\n",
    "    \n",
    "    img_resized = np.zeros(shape=(1, 3, h, w))\n",
    "    img_resized[0, 2, :, :] = cv2.resize(img[:, :, 0] - MEAN_VALUES[2], (h, w))\n",
    "    img_resized[0, 1, :, :] = cv2.resize(img[:, :, 1] - MEAN_VALUES[1], (h, w)) \n",
    "    img_resized[0, 0, :, :] = cv2.resize(img[:, :, 2] - MEAN_VALUES[0], (h, w)) \n",
    "    \n",
    "    return img_resized.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dir_path = 'data/train_subset/'\n",
    "\n",
    "file_names = os.listdir(dir_path)\n",
    "n_objects = len(file_names)\n",
    "\n",
    "y_train = []\n",
    "X_train = np.zeros(shape=(n_objects, 3, 32, 32), dtype='float32')\n",
    "\n",
    "MEAN_VALUES = [0, 0, 0]\n",
    "for i, f in enumerate(file_names):\n",
    "    img = scipy.misc.imread(dir_path + f)\n",
    "    y_train.append(f[:3] == 'cat')\n",
    "    MEAN_VALUES[2] += img[:, :, 0].mean()\n",
    "    MEAN_VALUES[1] += img[:, :, 1].mean()\n",
    "    MEAN_VALUES[0] += img[:, :, 2].mean()\n",
    "\n",
    "MEAN_VALUES = 1. * np.array(MEAN_VALUES) / n_objects\n",
    "y_train = np.array(y_train, dtype='int32')\n",
    "\n",
    "for i, f in enumerate(file_names):\n",
    "    img = scipy.misc.imread(dir_path + f)\n",
    "    X_train[i] = preprocess(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 3, 32, 32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape = list(X_train.shape)\n",
    "input_shape[0] = None\n",
    "input_shape = tuple(input_shape)\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PriorWeights(object):\n",
    "    def __init__(self, mode='W', prior='gauss', **params):\n",
    "        self.count = 0\n",
    "        self.prior = prior\n",
    "        self.mode = mode\n",
    "        params.setdefault('std', 1.)\n",
    "        params.setdefault('hyper', None)\n",
    "        params.setdefault('layer', '')\n",
    "        params.setdefault('pretrained', False)\n",
    "        self.params = params\n",
    "    def __call__(self, shape):\n",
    "        self.count += 1\n",
    "        if self.params['hyper'] is None:\n",
    "            std = self.params['std']\n",
    "        elif self.params['hyper'] == 'cauchy':\n",
    "            std = pm.HalfCauchy('hyper_%s%d' % (self.mode, self.count), beta=1.)\n",
    "        elif self.params['hyper'] == 'normal':\n",
    "            std = pm.HalfNormal('hyper_%s%d' % (self.mode, self.count), mu=0., sd=1.)\n",
    "        elif self.params['hyper'] == 'flat':\n",
    "            std = pm.Flat()\n",
    "            \n",
    "        if self.params['pretrained']:\n",
    "            tv = self.params['testval']\n",
    "        else:\n",
    "            tv = np.random.normal(size=shape).astype(np.float64)\n",
    "        \n",
    "        if self.prior == 'gauss':\n",
    "            return pm.Normal('%s%s%d' % (self.params['layer'], self.mode, self.count), mu=tv, sd=std, \n",
    "                         testval=np.random.normal(size=shape).astype(np.float64), shape=shape)\n",
    "        elif self.prior == 'laplace': \n",
    "            return pm.Laplace('%s%s%d' % (self.params['layer'], self.mode, self.count), mu=tv, b=std, \n",
    "                         testval=np.random.normal(size=shape).astype(np.float64), shape=shape)\n",
    "        elif self.prior == 'flat':\n",
    "            return pm.Flat('%s%s%d' % (self.params['layer'], self.mode, self.count), \n",
    "                           testval=np.random.normal(size=shape).astype(np.float64), shape=shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params_keys = ['conv1_1_W', 'conv1_1_b', 'conv1_2_W', 'conv1_2_b', \n",
    "            'conv2_1_W', 'conv2_1_b', 'conv2_2_W', 'conv2_2_b',\n",
    "            'conv3_1_W', 'conv3_1_b', 'conv3_2_W', 'conv3_2_b', 'conv3_3_W', 'conv3_3_b', 'conv3_4_W', 'conv3_4_b',\n",
    "            'conv4_1_W', 'conv4_1_b', 'conv4_2_W', 'conv4_2_b', 'conv4_3_W', 'conv4_3_b', 'conv4_4_W', 'conv4_4_b',\n",
    "            'conv5_1_W', 'conv5_1_b', 'conv5_2_W', 'conv5_2_b', 'conv5_3_W', 'conv5_3_b', 'conv5_4_W', 'conv5_4_b',\n",
    "            'fc6_W', 'fc6_b']#, 'fc7_W', 'fc7_b', 'fc8_W', 'fc8_b']\n",
    "\n",
    "params = np.load('vgg19.npz')['params']\n",
    "\n",
    "for i in range(32, len(params)): \n",
    "    params[i] = params[i].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 3, 3, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "priors = {}\n",
    "for i, param_key in enumerate(params_keys):\n",
    "    priors[param_key] = PriorWeights(mode=param_key[-1], prior='gauss', pretrained=True, \n",
    "                                     layer=param_key[:-1], testval=params[i])\n",
    "\n",
    "priors['fc6_W'] = PriorWeights(mode='W', prior='gauss')\n",
    "priors['fc6_b'] = PriorWeights(mode='b', prior='gauss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#vgg19 model\n",
    "#http://www.robots.ox.ac.uk/~vgg/research/very_deep/\n",
    "def build_ann(priors, input_var, target_var, \n",
    "              input_shape):\n",
    "\n",
    "    with pm.Model() as neural_network:\n",
    "        net = {}\n",
    "        net['input'] = InputLayer((None, 3, 64, 64), input_var=input_var)\n",
    "        net['conv1_1'] = ConvLayer(net['input'], 64, 3, pad=1,\n",
    "                                   W=priors['conv1_1_W'], b=priors['conv1_1_b'],\n",
    "                                   flip_filters=False)\n",
    "        net['conv1_2'] = ConvLayer(net['conv1_1'], 64, 3, pad=1,\n",
    "                                   W=priors['conv1_2_W'], b=priors['conv1_2_b'],\n",
    "                                   flip_filters=False)\n",
    "        net['pool1'] = PoolLayer(net['conv1_2'], 2)\n",
    "        net['conv2_1'] = ConvLayer(net['pool1'], 128, 3, pad=1,\n",
    "                                   W=priors['conv2_1_W'], b=priors['conv2_1_b'],\n",
    "                                   flip_filters=False)\n",
    "        net['conv2_2'] = ConvLayer(net['conv2_1'], 128, 3, pad=1,\n",
    "                                   W=priors['conv2_2_W'], b=priors['conv2_2_b'],\n",
    "                                   flip_filters=False)\n",
    "        net['pool2'] = PoolLayer(net['conv2_2'], 2)\n",
    "        net['conv3_1'] = ConvLayer(net['pool2'], 256, 3, pad=1,\n",
    "                                   W=priors['conv3_1_W'], b=priors['conv3_1_b'],\n",
    "                                   flip_filters=False)\n",
    "        net['conv3_2'] = ConvLayer(net['conv3_1'], 256, 3, pad=1,\n",
    "                                   W=priors['conv3_2_W'], b=priors['conv3_2_b'],\n",
    "                                   flip_filters=False)\n",
    "        net['conv3_3'] = ConvLayer(net['conv3_2'], 256, 3, pad=1,\n",
    "                                   W=priors['conv3_3_W'], b=priors['conv3_3_b'],\n",
    "                                   flip_filters=False)\n",
    "        net['conv3_4'] = ConvLayer(net['conv3_3'], 256, 3, pad=1,\n",
    "                                   W=priors['conv3_4_W'], b=priors['conv3_4_b'],\n",
    "                                   flip_filters=False)\n",
    "        net['pool3'] = PoolLayer(net['conv3_4'], 2)\n",
    "        net['conv4_1'] = ConvLayer(net['pool3'], 512, 3, pad=1,\n",
    "                                   W=priors['conv4_1_W'], b=priors['conv4_1_b'],\n",
    "                                   flip_filters=False)\n",
    "        net['conv4_2'] = ConvLayer(net['conv4_1'], 512, 3, pad=1,\n",
    "                                   W=priors['conv4_2_W'], b=priors['conv4_2_b'],\n",
    "                                   flip_filters=False)\n",
    "        net['conv4_3'] = ConvLayer(net['conv4_2'], 512, 3, pad=1,\n",
    "                                   W=priors['conv4_3_W'], b=priors['conv4_3_b'],\n",
    "                                   flip_filters=False)\n",
    "        net['conv4_4'] = ConvLayer(net['conv4_3'], 512, 3, pad=1,\n",
    "                                   W=priors['conv4_4_W'], b=priors['conv4_4_b'],\n",
    "                                   flip_filters=False)\n",
    "        net['pool4'] = PoolLayer(net['conv4_4'], 2)\n",
    "        net['conv5_1'] = ConvLayer(net['pool4'], 512, 3, pad=1,\n",
    "                                   W=priors['conv5_1_W'], b=priors['conv5_1_b'],\n",
    "                                   flip_filters=False)\n",
    "        net['conv5_2'] = ConvLayer(net['conv5_1'], 512, 3, pad=1,\n",
    "                                   W=priors['conv5_2_W'], b=priors['conv5_2_b'],\n",
    "                                   flip_filters=False)\n",
    "        net['conv5_3'] = ConvLayer(net['conv5_2'], 512, 3, pad=1,\n",
    "                                   W=priors['conv5_3_W'], b=priors['conv5_3_b'],\n",
    "                                   flip_filters=False)\n",
    "        net['conv5_4'] = ConvLayer(net['conv5_3'], 512, 3, pad=1,\n",
    "                                   W=priors['conv5_4_W'], b=priors['conv5_4_b'],\n",
    "                                   flip_filters=False)\n",
    "        net['pool5'] = PoolLayer(net['conv5_4'], 2)\n",
    "        net['fc6'] = DenseLayer(net['pool5'],\n",
    "                                   W=priors['fc6_W'], b=priors['fc6_b'],\n",
    "                                   num_units=2)\n",
    "#         net['fc6_dropout'] = DropoutLayer(net['fc6'], p=0.5)\n",
    "#         net['fc7'] = DenseLayer(net['fc6_dropout'], \n",
    "#                                    W=priors['fc7_W'], b=priors['fc7_b'],\n",
    "#                                    num_units=4096)\n",
    "#         net['fc7_dropout'] = DropoutLayer(net['fc7'], p=0.5)\n",
    "#         net['fc8'] = DenseLayer(net['fc7_dropout'], \n",
    "#                                    W=priors['fc8_W'], b=priors['fc8_b'],\n",
    "#                                    num_units=2, nonlinearity=None)\n",
    "        net['prob'] = NonlinearityLayer(net['fc6'], softmax)\n",
    "        \n",
    "        prediction = lasagne.layers.get_output(net['prob'])\n",
    "        \n",
    "        out = pm.Categorical('out', prediction,\n",
    "                           observed=target_var,\n",
    "                           total_size=y_train.shape[0])\n",
    "        \n",
    "    return neural_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_minibatch(data):\n",
    "    rng = np.random.RandomState(0)\n",
    "    \n",
    "    while True:\n",
    "        ixs = rng.randint(len(data), size=100)\n",
    "        yield data[ixs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_prediction(samples_proba):\n",
    "    return mode(np.argmax(sample_proba(X_test, 500), \n",
    "                          axis=-1), axis=0).mode[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "minibatch_X = pm.generator(create_minibatch(X_train))\n",
    "minibatch_y = pm.generator(create_minibatch(y_train))\n",
    "neural_network_minibatch = build_ann(priors, minibatch_X, minibatch_y, input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ADVI_ITERS = 5000\n",
    "N_SAMPLES = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with neural_network_minibatch:\n",
    "    inference = pm.ADVI()\n",
    "    approx = pm.fit(ADVI_ITERS, method=inference)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
